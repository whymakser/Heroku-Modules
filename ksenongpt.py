from .. import loader, utils
import requests
import io
import aiohttp
import logging

logger = logging.getLogger(__name__)

# meta developer: @kmodules
# changelog: Ğ¤Ğ¸ĞºÑÑ‹, Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ĞµÑÑŒ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ 

__version__ = (1, 5, 4)
version = __version__

@loader.tds
class KsenonGPTMod(loader.Module):
    """KsenonGPT module for text and image generation using KsenonAPI"""

    strings = {
        "name": "KsenonGPT",
        "no_api_key": "<emoji document_id=5881702736843511327>âš ï¸</emoji> <b>You have not set up the API key!</b>\n\n<emoji document_id=5879585266426973039>ğŸŒ</emoji> <b>The key is very easy to get, it's free.</b>\n\n<emoji document_id=6034962180875490251>ğŸ”“</emoji> <b>Bot: </b><b>@ksenonapi_gettoken_bot</b>",
        "generating_text": "<emoji document_id=5891243564309942507>ğŸ’¬</emoji> <b>Responding to your message...</b>",
        "text_generated": "<emoji document_id=5870984130560266604>ğŸ’¬</emoji> <b>Request:</b> <code>{}</code>\n\n<emoji document_id=5891243564309942507>ğŸ’¬</emoji> {}",
        "generating_image": "<emoji document_id=5766879414704935108>ğŸ–¼</emoji> <b>Generating image...</b>\n\n<emoji document_id=5994544674604322765>ğŸ¤–</emoji> <b>Model:</b> <code>{}</code>\n<emoji document_id=5877465816030515018>ğŸ”—</emoji> <b>Request:</b> <code>{}</code>",
        "image_generated": "<emoji document_id=5766879414704935108>ğŸ–¼</emoji> <b>Image generated!</b>\n\n<emoji document_id=5994544674604322765>ğŸ¤–</emoji> <b>Model:</b> <code>{}</code>\n<emoji document_id=5877465816030515018>ğŸ”—</emoji> <b>Request:</b> <code>{}</code>\n\n<emoji document_id=5877307202888273539>ğŸ“¥</emoji> <b>Link:</b> {}",
        "error_blocked": "<emoji document_id=5832546462478635761>ğŸ”’</emoji> <b>You have been blocked!</b>\n\n<emoji document_id=5879896690210639947>ğŸ—‘</emoji><b>NSFW | politics etc. generation is prohibited.</b>",
        "error_occurred": "<emoji document_id=5881702736843511327>âš ï¸</emoji> <b>An error occurred!</b>\n\n<emoji document_id=5967816500415827773>ğŸ’»</emoji> <b>Model:</b> {}\n<emoji document_id=5874986954180791957>ğŸ“¶</emoji> <b>Server status, code:</b> {}\n<emoji document_id=5832251986635920010>â¡ï¸</emoji> <b>Error:</b> {}",
        "text_models": "<emoji document_id=5879585266426973039>ğŸŒ</emoji> <b>Text models:</b>\n\n<blockquote>o1-preview\ngpt-4o\nclaude-3-5-sonnet\nsearchgpt (GPT + Internet)\nblackboxai-pro\nclaude-3-5-sonnet-20240620\nclaude-3-haiku-ddg\ngemini-1.5-pro-latest\nllama-3.1-405b\ngpt-3.5-turbo-202201\ngpt-4o-mini-ddg\ngpt-4o-2024-05-13\nmicrosoft/Phi-3.5-mini-instruct\nQwen/Qwen2.5-Coder-32B-Instruct\nQwen/QwQ-32B-Preview</blockquote>\n\n<emoji document_id=5843908536467198016>âœ…ï¸</emoji> <b>We have 150+ models!</b>\n<emoji document_id=5778423822940114949>ğŸ›¡</emoji><b><b> https://t.me/ksenonapi_models</b>",
        "image_models": "<emoji document_id=5879585266426973039>ğŸŒ</emoji> <b>Image models:</b>\n\n<blockquote><b>flux-pro-mg\nflux-dev\nsd3-ultra\npixart-alpha</b></blockquote>",
        "no_args": "<emoji document_id=5881702736843511327>âš ï¸</emoji> <b>No arguments provided!</b>",
        "update_available": "<emoji document_id=5420323339723881652>âš ï¸</emoji> <b>KsenonGPT update available!</b>\n\n<emoji document_id=5449683594425410231>ğŸ”¼</emoji> <b>New version: {}</b>\n<emoji document_id=5447183459602669338>ğŸ”½</emoji> <b>Current version: {}</b>\n\n<emoji document_id=5447410659077661506>ğŸŒ</emoji> <b>Changelog:</b>\n<emoji document_id=5458603043203327669>ğŸ””</emoji> <i>{}</i>\n\n<emoji document_id=5206607081334906820>âœ”ï¸</emoji> <b>Command to update:</b>\n<code>.dlmod https://raw.githubusercontent.com/TheKsenon/MyHikkaModules/refs/heads/main/ksenongpt.py</code>",
        "latest_version": "<emoji document_id=5370870691140737817>ğŸ¥³</emoji> <b>You have the latest version of KsenonGPT!</b>\n\n<emoji document_id=5447644880824181073>âš ï¸</emoji><b>Developers are making updates and fixes almost every day, check frequently!</b>",
        "select_model": "<b>ğŸ¤– Select AI model:\n\nğŸ”‘ You can also specify a model directly by using .setmodel model_name</b>",
        "model_set": "<b>ğŸ¯ Model has been set to: {}</b>",
        "invalid_model": "<b>âŒ Invalid model specified!</b>",
        "need_set_model": "<emoji document_id=5222148368955877900>ğŸ”¥</emoji> <b>Please set the model using .setmodel command!</b>"
    }

    strings_ru = {
        "name": "KsenonGPT",
        "no_api_key": "<emoji document_id=5881702736843511327>âš ï¸</emoji> <b>Ğ’Ñ‹ Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¸Ğ»Ğ¸ API ĞºĞ»ÑÑ‡!</b>\n\n<emoji document_id=5879585266426973039>ğŸŒ</emoji> <b>ĞšĞ»ÑÑ‡ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ»ĞµĞ³ĞºĞ¾ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚ÑŒ, Ğ¾Ğ½ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğ¹.</b>\n\n<emoji document_id=6034962180875490251>ğŸ”“</emoji> <b>Ğ‘Ğ¾Ñ‚: </b><b>@ksenonapi_gettoken_bot</b>",
        "generating_text": "<emoji document_id=5891243564309942507>ğŸ’¬</emoji> <b>ĞÑ‚Ğ²ĞµÑ‡Ğ°Ñ Ğ½Ğ° Ğ²Ğ°ÑˆĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ...</b>",
        "text_generated": "<emoji document_id=5870984130560266604>ğŸ’¬</emoji> <b>Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ:</b> <code>{}</code>\n\n<emoji document_id=5891243564309942507>ğŸ’¬</emoji> {}",
        "generating_image": "<emoji document_id=5766879414704935108>ğŸ–¼</emoji> <b>Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ...</b>\n\n<emoji document_id=5994544674604322765>ğŸ¤–</emoji> <b>ĞœĞ¾Ğ´ĞµĞ»ÑŒ:</b> <code>{}</code>\n<emoji document_id=5877465816030515018>ğŸ”—</emoji> <b>Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ:</b> <code>{}</code>",
        "image_generated": "<emoji document_id=5766879414704935108>ğŸ–¼</emoji> <b>Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾!</b>\n\n<emoji document_id=5994544674604322765>ğŸ¤–</emoji> <b>ĞœĞ¾Ğ´ĞµĞ»ÑŒ:</b> <code>{}</code>\n<emoji document_id=5877465816030515018>ğŸ”—</emoji> <b>Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ:</b> <code>{}</code>\n\n<emoji document_id=5877307202888273539>ğŸ“¥</emoji> <b>Ğ¡ÑÑ‹Ğ»ĞºĞ°:</b> {}",
        "error_blocked": "<emoji document_id=5832546462478635761>ğŸ”’</emoji> <b>Ğ’Ñ‹ Ğ±Ñ‹Ğ»Ğ¸ Ğ·Ğ°Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹!</b>\n\n<emoji document_id=5879896690210639947>ğŸ—‘</emoji><b>Ğ—Ğ°Ğ¿Ñ€ĞµÑ‰ĞµĞ½Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ NSFW | Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ¸ Ñ‚.Ğ´.</b>",
        "error_occurred": "<emoji document_id=5881702736843511327>âš ï¸</emoji> <b>ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ¾ÑˆĞ»Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ°!</b>\n\n<emoji document_id=5967816500415827773>ğŸ’»</emoji> <b>ĞœĞ¾Ğ´ĞµĞ»ÑŒ:</b> {}\n<emoji document_id=5874986954180791957>ğŸ“¶</emoji> <b>Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ ÑĞµÑ€Ğ²ĞµÑ€Ğ°, ĞºĞ¾Ğ´:</b> {}\n<emoji document_id=5832251986635920010>â¡ï¸</emoji> <b>ĞÑˆĞ¸Ğ±ĞºĞ°:</b> {}",
        "text_models": "<emoji document_id=5879585266426973039>ğŸŒ</emoji> <b>Ğ¢ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:</b>\n\n<blockquote>o1-preview\ngpt-4o\nclaude-3-5-sonnet\nsearchgpt (GPT + Internet)\nblackboxai-pro\nclaude-3-5-sonnet-20240620\nclaude-3-haiku-ddg\ngemini-1.5-pro-latest\nllama-3.1-405b\ngpt-3.5-turbo-202201\ngpt-4o-mini-ddg\ngpt-4o-2024-05-13\nmicrosoft/Phi-3.5-mini-instruct\nQwen/Qwen2.5-Coder-32B-Instruct\nQwen/QwQ-32B-Preview</blockquote>\n\n<emoji document_id=5843908536467198016>âœ…ï¸</emoji> <b>Ğ£ Ğ½Ğ°Ñ 150+ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹!</b>\n<emoji document_id=5778423822940114949>ğŸ›¡</emoji><b><b> https://t.me/ksenonapi_models</b>",
        "image_models": "<emoji document_id=5879585266426973039>ğŸŒ</emoji> <b>ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹:</b>\n\n<blockquote><b>flux-pro-mg\nflux-dev\nsd3-ultra\npixart-alpha</b></blockquote>",
        "no_args": "<emoji document_id=5881702736843511327>âš ï¸</emoji> <b>ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ñ‹ Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹!</b>",
        "update_available": "<emoji document_id=5420323339723881652>âš ï¸</emoji> <b>Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ KsenonGPT!</b>\n\n<emoji document_id=5449683594425410231>ğŸ”¼</emoji> <b>ĞĞ¾Ğ²Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ: {}</b>\n<emoji document_id=5447183459602669338>ğŸ”½</emoji> <b>Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ: {}</b>\n\n<emoji document_id=5447410659077661506>ğŸŒ</emoji> <b>Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹:</b>\n<emoji document_id=5458603043203327669>ğŸ””</emoji> <i>{}</i>\n\n<emoji document_id=5206607081334906820>âœ”ï¸</emoji> <b>ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ:</b>\n<code>.dlmod https://raw.githubusercontent.com/TheKsenon/MyHikkaModules/refs/heads/main/ksenongpt.py</code>",
        "latest_version": "<emoji document_id=5370870691140737817>ğŸ¥³</emoji> <b>Ğ£ Ğ²Ğ°Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ²ĞµÑ€ÑĞ¸Ñ KsenonGPT!</b>\n\n<emoji document_id=5447644880824181073>âš ï¸</emoji><b>Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸ Ğ´ĞµĞ»Ğ°ÑÑ‚ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ñ‡Ñ‚Ğ¸ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ´ĞµĞ½ÑŒ, Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞ¹Ñ‚Ğµ Ñ‡Ğ°Ñ‰Ğµ!</b>",
        "select_model": "<b>ğŸ¤– Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ˜Ğ˜ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ:\n\nğŸ”‘ Ğ¢Ğ°ĞºĞ¶Ğµ Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ ÑƒĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ .setmodel Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ_Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸</b>",
        "model_set": "<b>ğŸ¯ ĞœĞ¾Ğ´ĞµĞ»ÑŒ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°: {}</b>",
        "invalid_model": "<b>âŒ Ğ£ĞºĞ°Ğ·Ğ°Ğ½Ğ° Ğ½ĞµĞ²ĞµÑ€Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ!</b>",
        "need_set_model": "<emoji document_id=5222148368955877900>ğŸ”¥</emoji> <b>ĞŸĞ¾ÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² .setmodel!</b>"
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "api_key",
                "",
                "API key from @ksenonapi_gettoken_bot",
                validator=loader.validators.Hidden(),
            ),
            loader.ConfigValue(
                "default_model",
                "",
                "Default AI model to use",
            )
        )
        
    def _create_model_buttons(self):
        buttons = []
        models = [
            ("DeepSeek R1", "deepseek-r1"),
            ("GPT-4o", "gpt-4o"),
            ("Claude 3.5 Sonnet", "claude-3-5-sonnet"),
            ("SearchGPT", "searchgpt"),
            ("P1", "p1"),
            ("Gemini 2.0 Flash", "gemini-flash-2.0")
        ]
        
        row = []
        for i, (name, model_id) in enumerate(models):
            row.append({"text": name, "callback": self._set_model, "args": (model_id,)})
            if len(row) == 2:
                buttons.append(row)
                row = []
        if row:
            buttons.append(row)
            
        return buttons

    async def setmodelcmd(self, message):
        """Set default AI model for text generation"""
        args = utils.get_args_raw(message)
        if args:
            self.config["default_model"] = args
            await utils.answer(message, self.strings["model_set"].format(args))
            return

        await self.inline.form(
            text=self.strings["select_model"],
            message=message,
            reply_markup=self._create_model_buttons())

    async def _set_model(self, call, model):
        self.config["default_model"] = model
        await call.edit(
            self.strings["model_set"].format(model),
            reply_markup=None)

    async def gentextcmd(self, message):
        """Generate text - .gentext <prompt>"""
        if not self.config["api_key"]:
            await utils.answer(message, self.strings["no_api_key"])
            return

        if not self.config["default_model"]:
            await utils.answer(message, self.strings["need_set_model"])
            return

        args = utils.get_args_raw(message)
        if not args:
            await utils.answer(message, self.strings["no_args"])
            return

        prompt = args
        model = self.config["default_model"]

        msg = await utils.answer(message, self.strings["generating_text"])

        headers = {
            "Authorization": self.config["api_key"],
            "Content-Type": "application/json"
        }

        data = {
            "model": model,
            "prompt": prompt
        }

        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://aeza.theksenon.pro/v1/api/text/generate",
                headers=headers,
                json=data
            ) as response:
                result = await response.json()

                if response.status != 200:
                    await utils.answer(
                        msg,
                        self.strings["error_occurred"].format(
                            model,
                            response.status,
                            result.get("error", "Unknown error")
                        )
                    )
                    return

                if "error" in result:
                    if result["error"] == "Your token has been blocked":
                        await utils.answer(msg, self.strings["error_blocked"])
                        return

                    await utils.answer(
                        msg,
                        self.strings["error_occurred"].format(
                            model,
                            "N/A",
                            result["error"]
                        )
                    )
                    return

                await utils.answer(
                    msg,
                    self.strings["text_generated"].format(
                        prompt,
                        result["response"]
                    )
                )

    async def genimgcmd(self, message):
        """Generate image - .genimg <prompt> <model>"""
        if not self.config["api_key"]:
            await utils.answer(message, self.strings["no_api_key"])
            return

        args = utils.get_args_raw(message)
        if not args:
            await utils.answer(message, self.strings["no_args"])
            return

        try:
            prompt, model = args.rsplit(maxsplit=1)
        except ValueError:
            prompt = args
            model = "flux-pro-mg"

        msg = await utils.answer(
            message,
            self.strings["generating_image"].format(model, prompt)
        )

        headers = {
            "Authorization": self.config["api_key"],
            "Content-Type": "application/json"
        }

        data = {
            "model": model,
            "prompt": prompt
        }

        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://aeza.theksenon.pro/v1/api/image/generate",
                headers=headers,
                json=data
            ) as response:
                result = await response.json()

                if response.status != 200:
                    await utils.answer(
                        msg,
                        self.strings["error_occurred"].format(
                            model,
                            response.status,
                            result.get("error", "Unknown error")
                        )
                    )
                    return

                if "error" in result:
                    if result["error"] == "Your token has been blocked":
                        await utils.answer(msg, self.strings["error_blocked"])
                        return

                    await utils.answer(
                        msg,
                        self.strings["error_occurred"].format(
                            model,
                            "N/A",
                            result["error"]
                        )
                    )
                    return

                image_url = result["url"]
                async with session.get(image_url) as response:
                    if response.status != 200:
                        await utils.answer(
                            msg,
                            self.strings["error_occurred"].format(
                                model,
                                response.status,
                                "Failed to download image"
                            )
                        )
                        return

                    image_data = io.BytesIO(await response.read())
                    image_data.name = "image.png"

                    await self._client.send_file(
                        message.peer_id,
                        image_data,
                        caption=self.strings["image_generated"].format(
                            model,
                            prompt,
                            image_url
                        ),
                        reply_to=message.reply_to_msg_id
                    )

                    if message.out:
                        await message.delete()

    async def txtmodelscmd(self, message):
        """List of text models"""
        await utils.answer(message, self.strings["text_models"])

    async def imgmodelscmd(self, message):
        """List of image models"""
        await utils.answer(message, self.strings["image_models"])
        
    async def kupdatecmd(self, message):
        """Check for updates"""
        async with aiohttp.ClientSession() as session:
            async with session.get("https://raw.githubusercontent.com/TheKsenon/MyHikkaModules/refs/heads/main/ksenongpt.py") as response:
                if response.status != 200:
                    return
                    
                content = await response.text()
                
                try:
                    version_line = [line for line in content.split("\n") if "__version__" in line][0]
                    latest_version = tuple(map(int, version_line.split("(")[1].split(")")[0].split(",")))
                    
                    if latest_version > version:
                        changelog = "New version available!" 
                        
                        await utils.answer(
                            message,
                            self.strings["update_available"].format(
                                ".".join(map(str, latest_version)),
                                ".".join(map(str, version)),
                                changelog
                            )
                        )
                    else:
                        await utils.answer(message, self.strings["latest_version"])
                except:
                    logger.error("Failed to parse version from GitHub")
